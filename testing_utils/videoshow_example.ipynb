{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline \n",
    "import cv2\n",
    "import keras\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image \n",
    "import pickle\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from scipy.misc import imread, imresize\n",
    "from timeit import default_timer as timer\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from ssd_utils import BBoxUtility\n",
    "from ssd import SSD300 as SSD\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "video_path = 'videoplayback.mp4'\n",
    "weights_path = '../weights_SSD300.hdf5'\n",
    "class_names = [\"background\", \"stop_signs\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoTest(object):\n",
    "    def __init__(self, class_names, model, input_shape):\n",
    "        self.class_names = class_names\n",
    "        self.num_classes = len(class_names)\n",
    "        self.model = model\n",
    "        self.input_shape = input_shape\n",
    "        self.bbox_util = BBoxUtility(self.num_classes)\n",
    "        \n",
    "        # Create unique and somewhat visually distinguishable bright\n",
    "        # colors for the different classes.\n",
    "        self.class_colors = []\n",
    "        for i in range(0, self.num_classes):\n",
    "            # This can probably be written in a more elegant manner\n",
    "            hue = 255*i/self.num_classes\n",
    "            col = np.zeros((1,1,3)).astype(\"uint8\")\n",
    "            col[0][0][0] = hue\n",
    "            col[0][0][1] = 128 # Saturation\n",
    "            col[0][0][2] = 255 # Value\n",
    "            cvcol = cv2.cvtColor(col, cv2.COLOR_HSV2BGR)\n",
    "            col = (int(cvcol[0][0][0]), int(cvcol[0][0][1]), int(cvcol[0][0][2]))\n",
    "            self.class_colors.append(col) \n",
    "        \n",
    "    def run(self, video_path = 0, start_frame = 0, conf_thresh = 0.6):\n",
    "        vid = cv2.VideoCapture(video_path)\n",
    "        if not vid.isOpened():\n",
    "            raise IOError((\"Couldn't open video file or webcam. If you're \"\n",
    "            \"trying to open a webcam, make sure you video_path is an integer!\"))\n",
    "        \n",
    "        # Compute aspect ratio of video     \n",
    "        vidw = vid.get(3)\n",
    "        vidh = vid.get(4)\n",
    "        vidar = vidw/vidh\n",
    "        \n",
    "        # Skip frames until reaching start_frame\n",
    "        if start_frame > 0:\n",
    "            vid.set(cv2.cv.CV_CAP_PROP_POS_MSEC, start_frame)\n",
    "            \n",
    "        accum_time = 0\n",
    "        curr_fps = 0\n",
    "        fps = \"FPS: ??\"\n",
    "        prev_time = timer()\n",
    "            \n",
    "        while True:\n",
    "            retval, orig_image = vid.read()\n",
    "            if not retval:\n",
    "                print(\"Done!\")\n",
    "                return\n",
    "                \n",
    "            im_size = (self.input_shape[0], self.input_shape[1])    \n",
    "            resized = cv2.resize(orig_image, im_size)\n",
    "            rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Reshape to original aspect ratio for later visualization\n",
    "            # The resized version is used, to visualize what kind of resolution\n",
    "            # the network has to work with.\n",
    "            to_draw = cv2.resize(resized, (int(self.input_shape[0]*vidar), self.input_shape[1]))\n",
    "            \n",
    "            # Use model to predict \n",
    "            inputs = [image.img_to_array(rgb)]\n",
    "            tmp_inp = np.array(inputs)\n",
    "            x = preprocess_input(tmp_inp)\n",
    "            \n",
    "            y = self.model.predict(x)\n",
    "            \n",
    "            \n",
    "            # This line creates a new TensorFlow device every time. Is there a \n",
    "            # way to avoid that?\n",
    "            results = self.bbox_util.detection_out(y)\n",
    "            \n",
    "            if len(results) > 0 and len(results[0]) > 0:\n",
    "                # Interpret output, only one frame is used \n",
    "                det_label = results[0][:, 0]\n",
    "                det_conf = results[0][:, 1]\n",
    "                det_xmin = results[0][:, 2]\n",
    "                det_ymin = results[0][:, 3]\n",
    "                det_xmax = results[0][:, 4]\n",
    "                det_ymax = results[0][:, 5]\n",
    "\n",
    "                top_indices = [i for i, conf in enumerate(det_conf) if conf >= conf_thresh]\n",
    "\n",
    "                top_conf = det_conf[top_indices]\n",
    "                top_label_indices = det_label[top_indices].tolist()\n",
    "                top_xmin = det_xmin[top_indices]\n",
    "                top_ymin = det_ymin[top_indices]\n",
    "                top_xmax = det_xmax[top_indices]\n",
    "                top_ymax = det_ymax[top_indices]\n",
    "\n",
    "                for i in range(top_conf.shape[0]):\n",
    "                    xmin = int(round(top_xmin[i] * to_draw.shape[1]))\n",
    "                    ymin = int(round(top_ymin[i] * to_draw.shape[0]))\n",
    "                    xmax = int(round(top_xmax[i] * to_draw.shape[1]))\n",
    "                    ymax = int(round(top_ymax[i] * to_draw.shape[0]))\n",
    "\n",
    "                    # Draw the box on top of the to_draw image\n",
    "                    class_num = int(top_label_indices[i])\n",
    "                    cv2.rectangle(to_draw, (xmin, ymin), (xmax, ymax), \n",
    "                                  self.class_colors[class_num], 2)\n",
    "                    text = self.class_names[class_num] + \" \" + ('%.2f' % top_conf[i])\n",
    "\n",
    "                    text_top = (xmin, ymin-10)\n",
    "                    text_bot = (xmin + 80, ymin + 5)\n",
    "                    text_pos = (xmin + 5, ymin)\n",
    "                    cv2.rectangle(to_draw, text_top, text_bot, self.class_colors[class_num], -1)\n",
    "                    cv2.putText(to_draw, text, text_pos, cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0,0,0), 1)\n",
    "            \n",
    "            # Calculate FPS\n",
    "            # This computes FPS for everything, not just the model's execution \n",
    "            # which may or may not be what you want\n",
    "            curr_time = timer()\n",
    "            exec_time = curr_time - prev_time\n",
    "            prev_time = curr_time\n",
    "            accum_time = accum_time + exec_time\n",
    "            curr_fps = curr_fps + 1\n",
    "            if accum_time > 1:\n",
    "                accum_time = accum_time - 1\n",
    "                fps = \"FPS: \" + str(curr_fps)\n",
    "                curr_fps = 0\n",
    "            \n",
    "            # Draw FPS in top left corner\n",
    "            cv2.rectangle(to_draw, (0,0), (50, 17), (255,255,255), -1)\n",
    "            cv2.putText(to_draw, fps, (3,10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0,0,0), 1)\n",
    "            videostream = cv2.cvtColor(to_draw, cv2.COLOR_BGR2RGB)\n",
    "            axis('off')\n",
    "            title('output stream')\n",
    "            imshow(videostream)\n",
    "            show()\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../ssd.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_1\", padding=\"same\")`\n",
      "  name='conv1_1')(net['input'])\n",
      "../ssd.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_2\", padding=\"same\")`\n",
      "  name='conv1_2')(net['conv1_1'])\n",
      "../ssd.py:46: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool1\", padding=\"same\")`\n",
      "  name='pool1')(net['conv1_2'])\n",
      "../ssd.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_1\", padding=\"same\")`\n",
      "  name='conv2_1')(net['pool1'])\n",
      "../ssd.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_2\", padding=\"same\")`\n",
      "  name='conv2_2')(net['conv2_1'])\n",
      "../ssd.py:57: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool2\", padding=\"same\")`\n",
      "  name='pool2')(net['conv2_2'])\n",
      "../ssd.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_1\", padding=\"same\")`\n",
      "  name='conv3_1')(net['pool2'])\n",
      "../ssd.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_2\", padding=\"same\")`\n",
      "  name='conv3_2')(net['conv3_1'])\n",
      "../ssd.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_3\", padding=\"same\")`\n",
      "  name='conv3_3')(net['conv3_2'])\n",
      "../ssd.py:72: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool3\", padding=\"same\")`\n",
      "  name='pool3')(net['conv3_3'])\n",
      "../ssd.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_1\", padding=\"same\")`\n",
      "  name='conv4_1')(net['pool3'])\n",
      "../ssd.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_2\", padding=\"same\")`\n",
      "  name='conv4_2')(net['conv4_1'])\n",
      "../ssd.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_3\", padding=\"same\")`\n",
      "  name='conv4_3')(net['conv4_2'])\n",
      "../ssd.py:87: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool4\", padding=\"same\")`\n",
      "  name='pool4')(net['conv4_3'])\n",
      "../ssd.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_1\", padding=\"same\")`\n",
      "  name='conv5_1')(net['pool4'])\n",
      "../ssd.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_2\", padding=\"same\")`\n",
      "  name='conv5_2')(net['conv5_1'])\n",
      "../ssd.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_3\", padding=\"same\")`\n",
      "  name='conv5_3')(net['conv5_2'])\n",
      "../ssd.py:102: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), strides=(1, 1), name=\"pool5\", padding=\"same\")`\n",
      "  name='pool5')(net['conv5_3'])\n",
      "/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:755: UserWarning: The `AtrousConvolution2D` layer  has been deprecated. Use instead the `Conv2D` layer with the `dilation_rate` argument.\n",
      "  warnings.warn('The `AtrousConvolution2D` layer '\n",
      "/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:759: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\", name=\"fc6\", dilation_rate=(6, 6), padding=\"same\")`\n",
      "  return Conv2D(*args, **kwargs)\n",
      "../ssd.py:110: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), activation=\"relu\", name=\"fc7\", padding=\"same\")`\n",
      "  border_mode='same', name='fc7')(net['fc6'])\n",
      "../ssd.py:115: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", name=\"conv6_1\", padding=\"same\")`\n",
      "  name='conv6_1')(net['fc7'])\n",
      "../ssd.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv6_2\", strides=(2, 2), padding=\"same\")`\n",
      "  name='conv6_2')(net['conv6_1'])\n",
      "../ssd.py:122: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"conv7_1\", padding=\"same\")`\n",
      "  name='conv7_1')(net['conv6_2'])\n",
      "../ssd.py:126: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv7_2\", strides=(2, 2), padding=\"valid\")`\n",
      "  name='conv7_2')(net['conv7_2'])\n",
      "../ssd.py:130: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"conv8_1\", padding=\"same\")`\n",
      "  name='conv8_1')(net['conv7_2'])\n",
      "../ssd.py:133: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv8_2\", strides=(2, 2), padding=\"same\")`\n",
      "  name='conv8_2')(net['conv8_1'])\n",
      "../ssd.py:140: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), name=\"conv4_3_norm_mbox_loc\", padding=\"same\")`\n",
      "  name='conv4_3_norm_mbox_loc')(net['conv4_3_norm'])\n",
      "../ssd.py:148: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, (3, 3), name=\"conv4_3_norm_mbox_conf_2\", padding=\"same\")`\n",
      "  name=name)(net['conv4_3_norm'])\n",
      "../ssd.py:160: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"fc7_mbox_loc\", padding=\"same\")`\n",
      "  name='fc7_mbox_loc')(net['fc7'])\n",
      "../ssd.py:168: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), name=\"fc7_mbox_conf_2\", padding=\"same\")`\n",
      "  name=name)(net['fc7'])\n",
      "../ssd.py:178: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv6_2_mbox_loc\", padding=\"same\")`\n",
      "  name='conv6_2_mbox_loc')(net['conv6_2'])\n",
      "../ssd.py:186: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), name=\"conv6_2_mbox_conf_2\", padding=\"same\")`\n",
      "  name=name)(net['conv6_2'])\n",
      "../ssd.py:197: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv7_2_mbox_loc\", padding=\"same\")`\n",
      "  name='conv7_2_mbox_loc')(net['conv7_2'])\n",
      "../ssd.py:205: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), name=\"conv7_2_mbox_conf_2\", padding=\"same\")`\n",
      "  name=name)(net['conv7_2'])\n",
      "../ssd.py:216: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv8_2_mbox_loc\", padding=\"same\")`\n",
      "  name='conv8_2_mbox_loc')(net['conv8_2'])\n",
      "../ssd.py:224: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), name=\"conv8_2_mbox_conf_2\", padding=\"same\")`\n",
      "  name=name)(net['conv8_2'])\n",
      "../ssd.py:258: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  mode='concat', concat_axis=1, name='mbox_loc')\n",
      "/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "../ssd.py:265: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  mode='concat', concat_axis=1, name='mbox_conf')\n",
      "../ssd.py:273: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name='mbox_priorbox')\n",
      "../ssd.py:288: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name='predictions')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 3 and 63 for 'Assign_43' (op: 'Assign') with input shapes: [3,3,512,6], [63,512,3,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 3 and 63 for 'Assign_43' (op: 'Assign') with input shapes: [3,3,512,6], [63,512,3,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a38661fd282e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mvid_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvid_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2620\u001b[0m             \u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2622\u001b[0;31m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                              ' elements.')\n\u001b[1;32m   3142\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2245\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2246\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2247\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2248\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking)\u001b[0m\n\u001b[1;32m    571\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \"\"\"\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    274\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    275\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    277\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     55\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 3 and 63 for 'Assign_43' (op: 'Assign') with input shapes: [3,3,512,6], [63,512,3,3]."
     ]
    }
   ],
   "source": [
    "input_shape = (300,300,3)\n",
    "NUM_CLASSES = len(class_names)\n",
    "model = SSD(input_shape, num_classes=NUM_CLASSES)\n",
    "model.load_weights(weights_path) \n",
    "vid_test = VideoTest(class_names, model, input_shape)\n",
    "vid_test.run(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
